{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e76cde",
   "metadata": {},
   "source": [
    "The aim: To use estimated parameter inputs in a sampling technique to outpute a synthetic time series dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970012ac",
   "metadata": {},
   "source": [
    "Method 1: To sample from a probability distribution and generate synthetic time series data based on estimates or intial guesses of the parameters.\n",
    "\n",
    "# Bayesian Inference with MCMC \n",
    "\n",
    "Explanation of method: Bayesian inference is a pwoerful framework that allows you to estimate probability distributions of parameters given observed data. By combining Bayesian inference with MCMC sampling techniques, you can sample from the posterior distribution of the parameters and generate synthetic time series data that reflects the uncertainty in the parameter estimates.This involves specifying prior distributions for the parameters, formulating the likelihood function based on the synthetic data and using MCMC method to sample from the join posterior distribution of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9bdcf7",
   "metadata": {},
   "source": [
    "Pseudocode / breakdown of the stages involved in generating a time series dataset using Bayesian inference with MCMC\n",
    "\n",
    "### Step 1: Define the model \n",
    "Specify the mathematical model that describes the time series data generation process. This includes equations, function or algorithms that related the parameters to the time series data.\n",
    "\n",
    "### Step 2: Define the Priors\n",
    "Specify the prior distribution for the parameters. Priors represet your beliefs or knowlege about the parameter values before observing the data. You can choose appropriate probability distributions based on your understanding of the problem\n",
    "\n",
    "### Step 3: Define the likelihood\n",
    "Formulate the likelihood function that describes the probability of observing the data given the prameters. The likelihood represents the statistical relationship between the parameters and the observed time series data.\n",
    "\n",
    "### Step 4: Define the Posterior\n",
    "Calculate the posterior distribution of the parameters using Bayes Theorem. The posterior is proportional to the product of the prior and the likelihood.\n",
    "\n",
    "### Step 5: MCMC Sampling \n",
    "Implement an MCMC sampling algorithm. 2 possibilities are Metropolis-Hastings algo or the Hamiltonian Monte Carlo algo. These MCMC sampling algos are to sample from the posterior distribution. MCMC lets you explore the parameter space and generate a chain of samples that are representive of the posterior distribution.\n",
    "\n",
    "### Step 6: Burn-in and Thinning\n",
    "\n",
    "Discard an intial portion of the MCMC samples to remove any dependence on the inital parameter values (burn-in). \n",
    "Then, thin out the remaining samples to reduce auto-colleration between successive samples and improves computational efficiency\n",
    "\n",
    "### Step 7: Generate synthetic dataset\n",
    "\n",
    "Use the retained MCMC samples to generate synthetic time series datasets. For each sample of the parameters, apply the model equations or algorithms to produce a corresponding synthetic time series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e1d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1151d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb4c6c",
   "metadata": {},
   "source": [
    "Step 1: Define the model\n",
    "\n",
    "\\begin{align}\n",
    "f(t, y) &= \\gamma + K\\left(e \\cos(\\omega) + \\cos{\\left(\\phi(t) + \\omega \\right)}\\right),\n",
    "\\quad \\phi = 2 {\\rm arc} \\tan \\left( \\sqrt{\\frac{1+e}{1 - e}}\\tan \\frac{E(t)}{2}\\right), \n",
    "\\quad E(t) = e \\sin(E(t)) + 2 \\pi \\frac{t - t_p}{P} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a2b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1: Define the model\n",
    "'''\n",
    "def genModel(t, y): #basically f(t, y) equation\n",
    "    gamma, K, e, omega, tp, P = y\n",
    "    phi = simulatePhi(t, y)\n",
    "    r1 = np.cos(phi + omega)\n",
    "    r2 = e*np.cos(omega)\n",
    "    f = gamma + K * (r1+r2)\n",
    "    return f\n",
    "\n",
    "def simulatePhi(t, y, steps = 10): #calculating numerical solutions to phi equation\n",
    "    gamma, K, e, omega, tp, P = y\n",
    "    s = tp\n",
    "    eta = t / (steps - 1)\n",
    "    E = 0\n",
    "    for it in range(steps):\n",
    "        s = s + eta\n",
    "        g = np.sqrt((1 + e)/(1 - e))*np.tan(E)/2 #Dr Colombos version I think the tan includes the E(t)/2 inside the brackets.\n",
    "        phi = 2 * np.arctan(g)  \n",
    "        E = e*np.sin(E) + 2*np.pi/P * (s - tp)\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474cebc",
   "metadata": {},
   "source": [
    "Step 2 -- Step 6\n",
    " Define priors, Define Likelihood, Define the posterior, MCMC Sampling, Burn-in and Thinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75a2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "def generateData(params, t):\n",
    "    with pm.Model() as model:\n",
    "        # Priors\n",
    "        gamma = pm.Normal('gamma', mu=params['gamma_mu'], sd=params['gamma_sd'])\n",
    "        K = pm.Normal('K', mu=params['K_mu'], sd=params['K_sd'])\n",
    "        e = pm.Uniform('e', lower=params['e_lower'], upper=params['e_upper'])\n",
    "        omega = pm.Normal('omega', mu=params['omega_mu'], sd=params['omega_sd'])\n",
    "        tp = pm.Normal('tp', mu=params['tp_mu'], sd=params['tp_sd'])\n",
    "        P = pm.Normal('P', mu=params['P_mu'], sd=params['P_sd'])\n",
    "        \n",
    "        #generate true trajectory\n",
    "        trueTrajectory = genModel(t, [gamma, K, e, omega, tp, P])\n",
    "        \n",
    "        #generate observed data\n",
    "        obsSTD = pm.HalfNormal('obs_sd', sd = params['obs_sd'])\n",
    "        \n",
    "        #likelihood \n",
    "        obs = pm.Normal('obs', mu = trueTrajectory, sd = obsSTD, observed = True)\n",
    "        \n",
    "        #perform MCMC sampling\n",
    "        \n",
    "        trace = pm.sample(params['n_samples'], tune=params['n_tune'], cores = params['n_cores'], random_seed = params['random_seed'], progressbar = False)\n",
    "        \n",
    "        #get the posterior distribution of the parameters\n",
    "        \n",
    "        posterior_samples = pm.trace_to_dataframe(trace, varnames = ['gamma', 'K', 'e', 'omega', 'tp', 'P'])\n",
    "        \n",
    "        #burn in and thinning\n",
    "        posterior_samples = posterior_samples[params['n_burn_in']::params['thinning']]\n",
    "        \n",
    "    return trueTrajectory, posterior_samples\n",
    "\n",
    "params = {\n",
    "    'gamma_mu': 0.01,\n",
    "    'gamma_sd': 0.01,\n",
    "    'K_mu': 10,\n",
    "    'K_sd': 1,\n",
    "    'e_lower': 0,\n",
    "    'e_upper': 1,\n",
    "    'omega_mu': 1,\n",
    "    'omega_sd': 0.1,\n",
    "    'tp_mu': 100,\n",
    "    'tp_sd': 10,\n",
    "    'P_mu': 1000,\n",
    "    'P_sd': 100,\n",
    "    'obs_sd': 0.1,\n",
    "    'n_samples': 1000,\n",
    "    'n_tune': 1000,\n",
    "    'n_cores': 1,\n",
    "    'random_seed': 12345,\n",
    "    'n_burn_in': 500,\n",
    "    'thinning': 2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b060a9",
   "metadata": {},
   "source": [
    "Step 7: Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40435130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/deprecat/classic.py:215: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  return wrapped_(*args_, **kwargs_)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: divide by zero encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: invalid value encountered in multiply\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: invalid value encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: invalid value encountered in add\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [obs_sd, P, tp, omega, e, K, gamma]\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: overflow encountered in exp\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/scalar/basic.py:1955: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return x / y\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/scalar/basic.py:2893: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(x)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: divide by zero encountered in impl (vectorized)\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: invalid value encountered in impl (vectorized)\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/theano/scalar/basic.py:1955: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return x / y\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Sampling 1 chain for 160 tune and 0 draw iterations (160 + 0 draws total) took 11154 seconds.\n",
      "No posterior samples. Unable to run convergence checks\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_585/1480384053.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrueTrajectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_585/2295203746.py\u001b[0m in \u001b[0;36mgenerateData\u001b[0;34m(params, t)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#get the posterior distribution of the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mposterior_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'omega'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#burn in and thinning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymc3/backends/tracetab.py\u001b[0m in \u001b[0;36mtrace_to_dataframe\u001b[0;34m(trace, chains, varnames, include_transformed)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvarnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mflat_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mvar_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    }
   ],
   "source": [
    "t = np.arange(0, 1000)\n",
    "trueTrajectory, posterior_samples = generateData(params, t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f40f4",
   "metadata": {},
   "source": [
    "Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9541a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
